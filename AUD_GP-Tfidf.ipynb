{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e8a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1fe234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Resume'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Nikhi\\Desktop\\Files\\Resume\\Resume\\Final_Resume.csv\")\n",
    "df.columns \n",
    "list1=df['Category'].value_counts().index\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb6d5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2316, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts(dropna=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abf2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string  \n",
    "    for ele in s: \n",
    "        str1 = str1+\" \"+ele  \n",
    "    \n",
    "    # return string  \n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abee75a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR                           153\n",
       "Business Development         120\n",
       "INFORMATION-TECHNOLOGY       119\n",
       "FITNESS                      117\n",
       "CONSULTANT                   115\n",
       "ADVOCATE                     115\n",
       "SALES                        115\n",
       "HEALTHCARE                   113\n",
       "DESIGNER                     106\n",
       "TEACHER                      102\n",
       "DIGITAL-MEDIA                 95\n",
       "Java Developer                84\n",
       "Testing                       70\n",
       "AGRICULTURE                   63\n",
       "DevOps Engineer               55\n",
       "Python Developer              48\n",
       "Web Designing                 45\n",
       "Hadoop                        42\n",
       "Operations Manager            40\n",
       "Mechanical Engineer           40\n",
       "Sales                         40\n",
       "Blockchain                    40\n",
       "ETL Developer                 40\n",
       "Data Science                  40\n",
       "Arts                          36\n",
       "AUTOMOBILE                    35\n",
       "Database                      33\n",
       "PMO                           30\n",
       "Electrical Engineering        30\n",
       "Health and fitness            30\n",
       "Business Analyst              28\n",
       "DotNet Developer              28\n",
       "Automation Testing            26\n",
       "Network Security Engineer     25\n",
       "SAP Developer                 24\n",
       "Civil Engineer                24\n",
       "BPO                           21\n",
       "Advocate                      20\n",
       "CHEF                           9\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89a7ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "df['target'] = labelencoder.fit_transform(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13ce0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts().sort_index()\n",
    "y=df[['target']]\n",
    "X=df[['Resume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a5c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.3,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b53fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 1)\n",
      "(1621, 1)\n",
      "(695, 1)\n",
      "(695, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28cff109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data into training data \n",
    "#Tokenize the collection \n",
    "token_list=[]\n",
    "for i in X_train['Resume']:\n",
    "    token_list.append(nltk.word_tokenize(i))\n",
    "#print(len(token_list))\n",
    "#Lammetize the words \n",
    "lammetize_list=[]\n",
    "for i in token_list:\n",
    "    lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_token=[lemmatizer.lemmatize(token) for token in i]\n",
    "    lammetize_list.append(lemmatized_token)\n",
    "#Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_list=[]\n",
    "for i in lammetize_list:\n",
    "    stop_words_removed = [token for token in i if not token in stopwords.words('english') if token.isalpha()]\n",
    "    stop_list.append(stop_words_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82096ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7807\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>director</th>\n",
       "      <th>summary</th>\n",
       "      <th>to</th>\n",
       "      <th>continue</th>\n",
       "      <th>career</th>\n",
       "      <th>organization</th>\n",
       "      <th>utilize</th>\n",
       "      <th>management</th>\n",
       "      <th>supervision</th>\n",
       "      <th>...</th>\n",
       "      <th>detroit</th>\n",
       "      <th>pathways</th>\n",
       "      <th>italy</th>\n",
       "      <th>suffolk</th>\n",
       "      <th>releasing</th>\n",
       "      <th>conferences</th>\n",
       "      <th>slow</th>\n",
       "      <th>offset</th>\n",
       "      <th>compression</th>\n",
       "      <th>ims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  director  summary   to  continue  career  organization  utilize  \\\n",
       "0    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "1    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "2    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "3    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "4    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "\n",
       "   management  supervision  ...  detroit  pathways  italy  suffolk  releasing  \\\n",
       "0         0.0     0.048203  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "1         0.0     0.015263  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "2         0.0     0.131084  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "3         0.0     0.000000  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "4         0.0     0.000000  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "\n",
       "   conferences  slow  offset  compression  ims  \n",
       "0          0.0   0.0     0.0          0.0  0.0  \n",
       "1          0.0   0.0     0.0          0.0  0.0  \n",
       "2          0.0   0.0     0.0          0.0  0.0  \n",
       "3          0.0   0.0     0.0          0.0  0.0  \n",
       "4          0.0   0.0     0.0          0.0  0.0  \n",
       "\n",
       "[5 rows x 7807 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list=[]\n",
    "for i in stop_list:\n",
    "    sentence_list=listToString(i)\n",
    "    final_list.append(sentence_list)\n",
    "#TFIDF min_df=3 and include 2-gram \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(min_df=5)\n",
    "v1=vectorizer.fit(final_list)\n",
    "v2=vectorizer.transform(final_list)\n",
    "print(len(v1.vocabulary_.keys()))\n",
    "X_train=pd.DataFrame(v2.toarray(),columns=v1.vocabulary_.keys())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182dd0d",
   "metadata": {},
   "source": [
    "## Preprocessing Done "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f5e4d",
   "metadata": {},
   "source": [
    "### Preparing the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a3f932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data into training data \n",
    "#Tokenize the collection \n",
    "token_list_test=[]\n",
    "for i in X_test['Resume']:\n",
    "    token_list_test.append(nltk.word_tokenize(i))\n",
    "#print(len(token_list))\n",
    "#Lammetize the words \n",
    "lammetize_list_test=[]\n",
    "for i in token_list_test:\n",
    "    lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_token=[lemmatizer.lemmatize(token) for token in i]\n",
    "    lammetize_list_test.append(lemmatized_token)\n",
    "#Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_list_test=[]\n",
    "for i in lammetize_list_test:\n",
    "    stop_words_removed = [token for token in i if not token in stopwords.words('english') if token.isalpha()]\n",
    "    stop_list_test.append(stop_words_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dfcc225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>director</th>\n",
       "      <th>summary</th>\n",
       "      <th>to</th>\n",
       "      <th>continue</th>\n",
       "      <th>career</th>\n",
       "      <th>organization</th>\n",
       "      <th>utilize</th>\n",
       "      <th>management</th>\n",
       "      <th>supervision</th>\n",
       "      <th>...</th>\n",
       "      <th>detroit</th>\n",
       "      <th>pathways</th>\n",
       "      <th>italy</th>\n",
       "      <th>suffolk</th>\n",
       "      <th>releasing</th>\n",
       "      <th>conferences</th>\n",
       "      <th>slow</th>\n",
       "      <th>offset</th>\n",
       "      <th>compression</th>\n",
       "      <th>ims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  director  summary   to  continue  career  organization  utilize  \\\n",
       "0    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "1    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "2    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "3    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "4    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "\n",
       "   management  supervision  ...  detroit  pathways  italy  suffolk  releasing  \\\n",
       "0         0.0     0.000000  ...      0.0       0.0    0.0      0.0   0.000000   \n",
       "1         0.0     0.000000  ...      0.0       0.0    0.0      0.0   0.000000   \n",
       "2         0.0     0.013431  ...      0.0       0.0    0.0      0.0   0.000000   \n",
       "3         0.0     0.000000  ...      0.0       0.0    0.0      0.0   0.206126   \n",
       "4         0.0     0.000000  ...      0.0       0.0    0.0      0.0   0.000000   \n",
       "\n",
       "   conferences  slow  offset  compression  ims  \n",
       "0          0.0   0.0     0.0          0.0  0.0  \n",
       "1          0.0   0.0     0.0          0.0  0.0  \n",
       "2          0.0   0.0     0.0          0.0  0.0  \n",
       "3          0.0   0.0     0.0          0.0  0.0  \n",
       "4          0.0   0.0     0.0          0.0  0.0  \n",
       "\n",
       "[5 rows x 7807 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list_test=[]\n",
    "for i in stop_list_test:\n",
    "    sentence_list=listToString(i)\n",
    "    final_list_test.append(sentence_list)\n",
    "#Changing it w.r.t Tfidf vector \n",
    "v_test=vectorizer.transform(final_list_test)\n",
    "X_test=pd.DataFrame(v_test.toarray(),columns=v1.vocabulary_.keys())\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5876e",
   "metadata": {},
   "source": [
    "### Model Development "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd853db3",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7512c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model Accuracy:: 58.1295%\n",
      "[2.12401152e-02 5.19043904e-03 7.92474112e-04 8.71472109e-05\n",
      " 1.55736086e-04 2.69874938e-04 2.54154352e-04 2.11621327e-04\n",
      " 1.04178368e-03 3.90572289e-02 4.28877055e-05 1.40182913e-01\n",
      " 1.67053174e-04 6.47950985e-03 1.02958954e-02 2.27365788e-04\n",
      " 5.67562049e-04 1.09699316e-03 2.72491005e-04 5.48743800e-04\n",
      " 2.00076675e-04 1.07645792e-02 2.70192360e-02 6.38856210e-02\n",
      " 3.37345812e-04 1.70252082e-04 6.48411342e-01 1.58871205e-03\n",
      " 2.19160545e-04 4.09077710e-04 1.32166627e-03 1.13299910e-03\n",
      " 3.75485175e-04 9.50692297e-03 2.08147893e-04 3.18241163e-04\n",
      " 4.50146919e-03 8.99378709e-04 5.48296955e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "## Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBmodel = MultinomialNB()\n",
    "# training\n",
    "NBmodel.fit(X_train, Y_train)\n",
    "y_pred_NB = NBmodel.predict(X_test)\n",
    "# evaluation\n",
    "acc_NB = accuracy_score(Y_test, y_pred_NB)\n",
    "print(\"Naive Bayes model Accuracy:: {:.4f}%\".format(acc_NB*100))\n",
    "y_pred_prob_nb = NBmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_nb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18380fe8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f31af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit model Accuracy:: 78.5612%\n",
      "[0.0305212  0.03546224 0.0151191  0.00454342 0.00574129 0.00632295\n",
      " 0.01217857 0.00504457 0.0216145  0.03924045 0.00352921 0.21131026\n",
      " 0.00487709 0.02302325 0.02293347 0.00584426 0.01099426 0.00891016\n",
      " 0.00668281 0.00758397 0.00551387 0.02226105 0.03999036 0.0265492\n",
      " 0.00600493 0.00568763 0.28872416 0.00917099 0.00610641 0.01147767\n",
      " 0.01489242 0.01519013 0.00577816 0.01664681 0.00841517 0.00595436\n",
      " 0.01308266 0.00864795 0.00842903]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logitmodel = LogisticRegression()\n",
    "# training\n",
    "Logitmodel.fit(X_train, Y_train)\n",
    "y_pred_logit = Logitmodel.predict(X_test)\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_logit = accuracy_score(Y_test, y_pred_logit)\n",
    "print(\"Logit model Accuracy:: {:.4f}%\".format(acc_logit*100))\n",
    "y_pred_prob_logit = Logitmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_logit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c07f2",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d09dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Accuracy: 78.1295%\n",
      "[0.   0.   0.05 0.   0.   0.   0.1  0.   0.   0.7  0.   0.   0.   0.\n",
      " 0.05 0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "DTmodel = DecisionTreeClassifier(min_samples_leaf=15,random_state=0) ## number of trees and number of layers/depth\n",
    "#training\n",
    "DTmodel.fit(X_train, Y_train)\n",
    "y_pred_DT = DTmodel.predict(X_test)\n",
    "#evaluation\n",
    "acc_DT = accuracy_score(Y_test, y_pred_DT)\n",
    "print(\"Decision Tree Model Accuracy: {:.4f}%\".format(acc_DT*100))\n",
    "y_pred_prob_dt = DTmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_dt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36324965",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5a6fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-73d962af1d78>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RFmodel.fit(X_train, Y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 82.5899%\n",
      "[[0.04922017 0.06470435 0.01819666 ... 0.01483242 0.00156554 0.00350868]\n",
      " [0.00161599 0.00144181 0.00052879 ... 0.00129277 0.00733971 0.00427683]\n",
      " [0.00379971 0.00431031 0.00245269 ... 0.00228748 0.00325932 0.00204288]\n",
      " ...\n",
      " [0.06054264 0.0670406  0.02164012 ... 0.02592004 0.00089612 0.00043333]\n",
      " [0.0974677  0.04853613 0.05830272 ... 0.03772399 0.00233307 0.0009003 ]\n",
      " [0.00741106 0.0068697  0.00280132 ... 0.00375406 0.01042701 0.00189173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "RFmodel = RandomForestClassifier(n_estimators=300, max_depth=20, bootstrap=True, random_state=0) ## number of trees and number of layers/depth\n",
    "#training\n",
    "RFmodel.fit(X_train, Y_train)\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "#evaluation\n",
    "acc_RF = accuracy_score(Y_test, y_pred_RF)\n",
    "print(\"Random Forest Model Accuracy: {:.4f}%\".format(acc_RF*100))\n",
    "y_pred_prob_rf = RFmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b217ff",
   "metadata": {},
   "source": [
    "### Xgboost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e9504c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgboost Classifier Model Accuracy: 86.4748%\n",
      "[1.1761621e-02 7.2640581e-03 4.1149547e-03 1.9815743e-03 1.1633310e-03\n",
      " 1.8930670e-03 4.3633631e-03 1.9105419e-03 2.4993049e-03 1.6739374e-03\n",
      " 2.1204802e-03 2.7527786e-03 1.9002861e-03 1.4039405e-03 1.9791087e-03\n",
      " 1.3203757e-03 1.6175081e-03 1.8070387e-03 2.2013725e-03 1.7692522e-03\n",
      " 1.7264521e-03 1.9522758e-03 2.2198623e-03 9.2957646e-04 1.9977733e-03\n",
      " 1.4498904e-03 9.0913767e-01 1.6711253e-03 1.6024767e-03 1.8391998e-03\n",
      " 1.8737979e-03 6.1954418e-03 1.7544897e-03 5.0640205e-04 1.9069267e-03\n",
      " 2.1829461e-03 6.9477194e-04 1.2321653e-03 1.6288331e-03]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgmodel = XGBClassifier(random_state=0) ## number of trees and number of layers/depth\n",
    "#training\n",
    "xgmodel.fit(X_train, Y_train)\n",
    "y_pred_xg = xgmodel.predict(X_test)\n",
    "#evaluation\n",
    "acc_xg = accuracy_score(Y_test, y_pred_xg)\n",
    "print(\"Xgboost Classifier Model Accuracy: {:.4f}%\".format(acc_xg*100))\n",
    "y_pred_prob_xg = xgmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_xg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b29ab",
   "metadata": {},
   "source": [
    "### Light GBM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75f72c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GMB Classifier Model Accuracy: 88.4892%\n",
      "[0.09281821 0.06987175 0.0050596  0.00276518 0.0031842  0.00386222\n",
      " 0.01021161 0.00879106 0.00436493 0.00717177 0.00199097 0.03667191\n",
      " 0.00504077 0.00323518 0.00802145 0.00362353 0.00589124 0.00771322\n",
      " 0.01021239 0.00579861 0.00644235 0.00606156 0.00940871 0.00360378\n",
      " 0.00877038 0.00312797 0.57603799 0.00587498 0.00491362 0.0069552\n",
      " 0.00655521 0.02939443 0.0078272  0.00401084 0.00408125 0.00537936\n",
      " 0.00589989 0.00487613 0.00447934]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgbmodel = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=0) ## number of trees and number of layers/depth\n",
    "#training\n",
    "lgbmodel.fit(X_train, Y_train, verbose=20,eval_metric='logloss')\n",
    "y_pred_lgb = lgbmodel.predict(X_test)\n",
    "#evaluation\n",
    "acc_lgb = accuracy_score(Y_test, y_pred_lgb)\n",
    "print(\"Light GMB Classifier Model Accuracy: {:.4f}%\".format(acc_lgb*100))\n",
    "y_pred_prob_lgb = lgbmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_lgb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d84baa",
   "metadata": {},
   "source": [
    "### CAT Boost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98a06640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.0811\n",
      "0:\tlearn: 3.4930195\ttotal: 4.62s\tremaining: 1h 16m 51s\n",
      "20:\tlearn: 2.0893365\ttotal: 1m 50s\tremaining: 1h 25m 42s\n",
      "40:\tlearn: 1.5184358\ttotal: 3m 29s\tremaining: 1h 21m 39s\n",
      "60:\tlearn: 1.1839601\ttotal: 5m 11s\tremaining: 1h 19m 58s\n",
      "80:\tlearn: 0.9377262\ttotal: 6m 55s\tremaining: 1h 18m 39s\n",
      "100:\tlearn: 0.7789476\ttotal: 8m 36s\tremaining: 1h 16m 41s\n",
      "120:\tlearn: 0.6504603\ttotal: 10m 24s\tremaining: 1h 15m 36s\n",
      "140:\tlearn: 0.5792521\ttotal: 12m 23s\tremaining: 1h 15m 32s\n",
      "160:\tlearn: 0.5372783\ttotal: 14m 27s\tremaining: 1h 15m 21s\n",
      "180:\tlearn: 0.5085818\ttotal: 16m 32s\tremaining: 1h 14m 50s\n",
      "200:\tlearn: 0.4886466\ttotal: 18m 50s\tremaining: 1h 14m 55s\n",
      "220:\tlearn: 0.4667099\ttotal: 21m 6s\tremaining: 1h 14m 25s\n",
      "240:\tlearn: 0.4484372\ttotal: 23m 19s\tremaining: 1h 13m 28s\n",
      "260:\tlearn: 0.4356245\ttotal: 25m 13s\tremaining: 1h 11m 25s\n",
      "280:\tlearn: 0.4192090\ttotal: 27m 7s\tremaining: 1h 9m 24s\n",
      "300:\tlearn: 0.4081948\ttotal: 29m 1s\tremaining: 1h 7m 23s\n",
      "320:\tlearn: 0.3977922\ttotal: 30m 55s\tremaining: 1h 5m 24s\n",
      "340:\tlearn: 0.3866946\ttotal: 32m 48s\tremaining: 1h 3m 24s\n",
      "360:\tlearn: 0.3758107\ttotal: 34m 40s\tremaining: 1h 1m 23s\n",
      "380:\tlearn: 0.3663125\ttotal: 36m 31s\tremaining: 59m 21s\n",
      "400:\tlearn: 0.3557853\ttotal: 38m 17s\tremaining: 57m 12s\n",
      "420:\tlearn: 0.3496212\ttotal: 40m\tremaining: 55m 1s\n",
      "440:\tlearn: 0.3389423\ttotal: 41m 59s\tremaining: 53m 13s\n",
      "460:\tlearn: 0.3321591\ttotal: 43m 40s\tremaining: 51m 4s\n",
      "480:\tlearn: 0.3246179\ttotal: 45m 26s\tremaining: 49m 2s\n",
      "500:\tlearn: 0.3155333\ttotal: 48m 11s\tremaining: 47m 59s\n",
      "520:\tlearn: 0.3096001\ttotal: 51m 8s\tremaining: 47m 1s\n",
      "540:\tlearn: 0.3026442\ttotal: 53m 58s\tremaining: 45m 52s\n",
      "560:\tlearn: 0.2947675\ttotal: 59m 10s\tremaining: 46m 28s\n",
      "580:\tlearn: 0.2884303\ttotal: 1h 1m 40s\tremaining: 44m 37s\n",
      "600:\tlearn: 0.2815542\ttotal: 1h 4m 14s\tremaining: 42m 47s\n",
      "620:\tlearn: 0.2768658\ttotal: 1h 7m\tremaining: 41m 1s\n",
      "640:\tlearn: 0.2705579\ttotal: 1h 9m 53s\tremaining: 39m 16s\n",
      "660:\tlearn: 0.2637183\ttotal: 1h 12m 36s\tremaining: 37m 21s\n",
      "680:\tlearn: 0.2561822\ttotal: 1h 15m 16s\tremaining: 35m 21s\n",
      "700:\tlearn: 0.2513042\ttotal: 1h 17m 56s\tremaining: 33m 20s\n",
      "720:\tlearn: 0.2451671\ttotal: 1h 20m 40s\tremaining: 31m 18s\n",
      "740:\tlearn: 0.2414276\ttotal: 1h 22m 42s\tremaining: 28m 59s\n",
      "760:\tlearn: 0.2376073\ttotal: 1h 24m 37s\tremaining: 26m 38s\n",
      "780:\tlearn: 0.2336044\ttotal: 1h 26m 28s\tremaining: 24m 18s\n",
      "800:\tlearn: 0.2308939\ttotal: 1h 28m 25s\tremaining: 22m 1s\n",
      "820:\tlearn: 0.2258149\ttotal: 1h 30m 27s\tremaining: 19m 46s\n",
      "840:\tlearn: 0.2227045\ttotal: 1h 32m 34s\tremaining: 17m 32s\n",
      "860:\tlearn: 0.2176393\ttotal: 1h 34m 27s\tremaining: 15m 17s\n",
      "880:\tlearn: 0.2158413\ttotal: 1h 36m 22s\tremaining: 13m 2s\n",
      "900:\tlearn: 0.2108381\ttotal: 1h 38m 12s\tremaining: 10m 48s\n",
      "920:\tlearn: 0.2068263\ttotal: 1h 40m 6s\tremaining: 8m 36s\n",
      "940:\tlearn: 0.2047715\ttotal: 1h 42m 5s\tremaining: 6m 24s\n",
      "960:\tlearn: 0.2018254\ttotal: 1h 44m 15s\tremaining: 4m 14s\n",
      "980:\tlearn: 0.1980616\ttotal: 1h 46m 18s\tremaining: 2m 3s\n",
      "999:\tlearn: 0.1953904\ttotal: 1h 48m 23s\tremaining: 0us\n",
      "Light GMB Classifier Model Accuracy: 88.4892%\n",
      "[2.47827069e-02 3.32238863e-02 1.53577819e-02 6.20432297e-04\n",
      " 8.85079900e-04 2.47278007e-03 2.45867250e-02 1.69220529e-03\n",
      " 5.87850428e-03 2.97973938e-02 3.22116103e-03 6.43185520e-02\n",
      " 7.04980755e-04 1.15213783e-02 1.77499341e-02 1.96241090e-03\n",
      " 5.36635551e-03 2.80493470e-03 1.23391098e-03 4.17112087e-03\n",
      " 9.60339806e-04 1.12088352e-02 1.42152372e-02 1.27599680e-02\n",
      " 3.46276478e-03 6.65818442e-04 6.64193905e-01 1.79589280e-03\n",
      " 8.64110963e-04 2.72769230e-03 3.98700488e-03 2.91813018e-03\n",
      " 1.69708294e-03 7.81484930e-03 6.03899400e-03 8.00707845e-04\n",
      " 7.21565907e-03 1.96333611e-03 2.35743689e-03]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "catmodel = CatBoostClassifier(random_state=0) ## number of trees and number of layers/depth\n",
    "#training\n",
    "catmodel.fit(X_train, Y_train, verbose=20)\n",
    "y_pred_cat = catmodel.predict(X_test)\n",
    "#evaluation\n",
    "acc_cat = accuracy_score(Y_test, y_pred_cat)\n",
    "print(\"Light GMB Classifier Model Accuracy: {:.4f}%\".format(acc_cat*100))\n",
    "y_pred_prob_cat = catmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f70e8f",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8af55bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Nikhi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL model Accuracy: 77.8417%\n",
      "[3.44776843e-014 2.90864003e-002 7.32153064e-005 6.44761011e-039\n",
      " 7.69575341e-045 2.43333955e-049 3.10798480e-004 1.29139326e-057\n",
      " 5.46242245e-042 1.15553460e-007 4.83438799e-023 7.37537377e-002\n",
      " 1.15272979e-055 4.97654444e-010 1.03477806e-007 1.25946895e-035\n",
      " 2.89261616e-022 9.28031475e-027 1.27332452e-032 7.44483765e-060\n",
      " 3.74197617e-055 2.83002448e-023 3.31994081e-005 1.61223486e-014\n",
      " 7.06984082e-060 3.16153372e-051 8.96742396e-001 1.52812841e-108\n",
      " 9.60738876e-033 2.34277170e-037 3.32141002e-018 6.71421071e-023\n",
      " 6.65874336e-052 1.26123275e-016 2.29928210e-030 7.13548170e-077\n",
      " 3.30307818e-008 9.05466559e-095 1.29087936e-070]\n"
     ]
    }
   ],
   "source": [
    "## Neural Network and Deep Learning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "DLmodel = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(150,1000), random_state=1)\n",
    "# training\n",
    "DLmodel.fit(X_train, Y_train)\n",
    "y_pred_DL= DLmodel.predict(X_test)\n",
    "# evaluation\n",
    "acc_DL = accuracy_score(Y_test, y_pred_DL)\n",
    "print(\"DL model Accuracy: {:.4f}%\".format(acc_DL*100))\n",
    "y_pred_prob_dl = DLmodel.predict_proba(X_test)\n",
    "print(y_pred_prob_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028e112",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfcde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "docs_x=df['Resume']\n",
    "docs_c=df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa452c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocab\n",
    "from collections import Counter\n",
    "words = [j for i in docs_x for j in i]\n",
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)\n",
    "vocab_to_int = {w: i+1 for i, (w,c) in enumerate(sorted_words)} # note 0 is for null\n",
    "# one hot\n",
    "text_int = [] \n",
    "for i in docs_x:\n",
    "    r = [vocab_to_int[w] for w in i]\n",
    "    text_int.append(r)\n",
    "# dummy label\n",
    "encoded_labels = [1 if label =='subj' else 0 for label in docs_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fe0c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-c258fcd0233e>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array(X_train_lstm)\n",
      "<ipython-input-9-c258fcd0233e>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test = np.array(X_test_lstm)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_lstm,X_test_lstm,Y_train_lstm,Y_test_lstm=train_test_split(text_int,encoded_labels,test_size=0.3,random_state=13)\n",
    "y_train = np.array(Y_train_lstm)\n",
    "y_test = np.array(Y_test_lstm)\n",
    "x_train = np.array(X_train_lstm)\n",
    "x_test = np.array(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dfcce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17/17 [==============================] - 46s 2s/step - loss: 0.6179 - accuracy: 0.9870 - val_loss: 0.4102 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.1294 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 40s 2s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 39s 2s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b0e4d69850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "import keras\n",
    "from keras.preprocessing import sequence \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "max_features = total_words\n",
    "maxlen = 200\n",
    "batch_size = 100\n",
    "# padding\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 20, input_length=maxlen))\n",
    "model.add(LSTM(40, dropout=0.20, recurrent_dropout=0.20))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24462e",
   "metadata": {},
   "source": [
    "### Cariglist Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44b5a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-5d55a9f1c547>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test1['selection1_selection2']=test1['selection1_selection2'].astype('str')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1510, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(r\"C:\\Users\\Nikhi\\Desktop\\Files\\Resume\\run_results_sfbay.csv\",dtype={'selection1_selection2':\"category\"})\n",
    "test1=test.dropna()\n",
    "test1['selection1_selection2']=test1['selection1_selection2'].astype('str')\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52eb5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['selection1_selection2'].to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\Resume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "531cf588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the collection \n",
    "token_test=[]\n",
    "j=0\n",
    "for i in test1['selection1_selection2']:\n",
    "    token_test.append(nltk.word_tokenize(i))\n",
    "#print(len(token_list))\n",
    "#Lammetize the words \n",
    "lammetize_test=[]\n",
    "for i in token_test:\n",
    "    lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_token=[lemmatizer.lemmatize(token) for token in i]\n",
    "    lammetize_test.append(lemmatized_token)\n",
    "#Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_test=[]\n",
    "for i in lammetize_test:\n",
    "    stop_words_removed = [token for token in i if not token in stopwords.words('english') if token.isalpha()]\n",
    "    stop_test.append(stop_words_removed)\n",
    "print(len(token_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d99b0f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>director</th>\n",
       "      <th>summary</th>\n",
       "      <th>to</th>\n",
       "      <th>continue</th>\n",
       "      <th>career</th>\n",
       "      <th>organization</th>\n",
       "      <th>utilize</th>\n",
       "      <th>management</th>\n",
       "      <th>supervision</th>\n",
       "      <th>...</th>\n",
       "      <th>detroit</th>\n",
       "      <th>pathways</th>\n",
       "      <th>italy</th>\n",
       "      <th>suffolk</th>\n",
       "      <th>releasing</th>\n",
       "      <th>conferences</th>\n",
       "      <th>slow</th>\n",
       "      <th>offset</th>\n",
       "      <th>compression</th>\n",
       "      <th>ims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  director  summary   to  continue  career  organization  utilize  \\\n",
       "0    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "1    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "2    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "3    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "4    0.0       0.0      0.0  0.0       0.0     0.0           0.0      0.0   \n",
       "\n",
       "   management  supervision  ...  detroit  pathways  italy  suffolk  releasing  \\\n",
       "0         0.0          0.0  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "1         0.0          0.0  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "2         0.0          0.0  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "3         0.0          0.0  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "4         0.0          0.0  ...      0.0       0.0    0.0      0.0        0.0   \n",
       "\n",
       "   conferences  slow  offset  compression  ims  \n",
       "0          0.0   0.0     0.0          0.0  0.0  \n",
       "1          0.0   0.0     0.0          0.0  0.0  \n",
       "2          0.0   0.0     0.0          0.0  0.0  \n",
       "3          0.0   0.0     0.0          0.0  0.0  \n",
       "4          0.0   0.0     0.0          0.0  0.0  \n",
       "\n",
       "[5 rows x 7807 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test=[]\n",
    "for i in stop_test:\n",
    "    sentence_list=listToString(i)\n",
    "    final_test.append(sentence_list)\n",
    "#Changing it w.r.t Tfidf vector \n",
    "v_test_c=vectorizer.transform(final_test)\n",
    "test=pd.DataFrame(v_test_c.toarray(),columns=v1.vocabulary_.keys())\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f668e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes \n",
    "y_pred_prob_nb = NBmodel.predict_proba(test)\n",
    "y_pred_prob_nb=pd.DataFrame(y_pred_prob_nb,columns=list1)\n",
    "y_pred_prob_nb.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_nb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7292724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression \n",
    "y_pred_prob_log = Logitmodel.predict_proba(test)\n",
    "y_pred_prob_log=pd.DataFrame(y_pred_prob_log,columns=list1)\n",
    "y_pred_prob_log.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45837115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "y_pred_prob_dt = DTmodel.predict_proba(test)\n",
    "y_pred_prob_dt=pd.DataFrame(y_pred_prob_dt,columns=list1)\n",
    "y_pred_prob_dt.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_dt.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "309a3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "y_pred_prob_rf = RFmodel.predict_proba(test)\n",
    "y_pred_prob_rf=pd.DataFrame(y_pred_prob_rf,columns=list1)\n",
    "y_pred_prob_rf.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "215a9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost \n",
    "y_pred_prob_xg = xgmodel.predict_proba(test)\n",
    "y_pred_prob_xg=pd.DataFrame(y_pred_prob_xg,columns=list1)\n",
    "y_pred_prob_xg.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_xg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ffa2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAT Boost\n",
    "y_pred_prob_cat = catmodel.predict_proba(test)\n",
    "y_pred_prob_cat=pd.DataFrame(y_pred_prob_cat,columns=list1)\n",
    "f=test1.merge(y_pred_prob_cat,left_index=True,right_index=True,how=\"inner\")\n",
    "f.columns\n",
    "#test.columns\n",
    "f.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e73dc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light GBM\n",
    "y_pred_prob_lgb = lgbmodel.predict_proba(test)\n",
    "y_pred_prob_lgb=pd.DataFrame(y_pred_prob_lgb,columns=list1)\n",
    "y_pred_prob_lgb.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_lgb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ddd94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN DLmodel\n",
    "y_pred_prob_ann = DLmodel.predict_proba(test)\n",
    "y_pred_prob_ann=pd.DataFrame(y_pred_prob_ann,columns=list1)\n",
    "y_pred_prob_ann.to_csv(r\"C:\\Users\\Nikhi\\OneDrive - purdue.edu\\Mod 2\\Analyzing Unstructured Data\\Group Project\\Results\\TFIDF\\y_pred_prob_ann.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b83095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
